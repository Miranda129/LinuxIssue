# 預設的logstash，聽tcp port 5000，並且把傳輸的資料直接送到elasticsearch
# input {
# 	tcp {
# 		port => 5000
# 	}
# }

# ## Add your filters / logstash plugins configuration here

# output {
# 	elasticsearch {
# 		hosts => "elasticsearch:9200"
# 	}
# }


input {
# filebeats 聽 5044 port 送過來的資料
   beats {
       port => 5044
   }

# 串接兩個nsq的消費者，並且對於不同消費者串接對應的topic以及channel
   nsq {
        nsqlookupd => ["nsqlookupd:4161"]
        topic => "topic_1"
        channel => "topic_1_consumer"
        max_in_flight  => 200
        codec => json
	tags => ['nsq_tag_1']
   }

   nsq {
        nsqlookupd => ["nsqlookupd:4161"]
        topic => "topic_2"
        channel => "topic_2_consumer"
        max_in_flight  => 200
        codec => json
	tags => ['nsq_tag_2']
   }
}

# 使用filter來過濾filebeat送過來的資料
filter {
  grok {
    match => {
      "message" => "%{GREEDYDATA:result}"
    }
  }
  json {
    source => "result"
  }
  mutate {
    remove_tag => ["_jsonparsefailure"]
  }
}


output {
# 將帶有[tags]的資料送到elasticsearch
    if 'nsq_tag_1' in [tags] {
		elasticsearch {
			hosts => "elasticsearch:9200"
			user => "elastic"
			password => "changeme"
			index => "nsq_index_1"
		}
    }

    if 'nsq_tag_2' in [tags] {
		elasticsearch {
			hosts => "elasticsearch:9200"
			user => "elastic"
			password => "changeme"
			index => "nsq_index_2"
		}
    }
    
# 增加filebeat輸出到elk
    if [type] == "nginxaccess" {
    	elasticsearch {
    	    hosts => "elasticsearch:9200"
    	    user => "elastic"
    	    password => "changeme"
    	    index => "nginxaccess"
    	}
        stdout { codec => rubydebug }
    }
}